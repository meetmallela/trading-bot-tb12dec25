"""
telegram_reader_jp_trained.py - ENHANCED VERSION
Telegram reader for JP channel using TRAINED agent
Uses KB with 184 human-verified corrections for 98%+ accuracy

NEW FEATURES:
- Shows NIFTY/SENSEX/BANKNIFTY expiry dates on startup
- Timestamped log files (telegram_jp_22JAN2026_14_30_45.log)
- Validates instruments loaded from CSV
- Graceful shutdown on SIGTERM/SIGINT
- Rate limiting to prevent API bans
- Explicit timezone handling (IST)
"""

import asyncio
import json
import sqlite3
import sys
import io
import signal
import time
from datetime import datetime
from collections import deque, defaultdict
from telethon import TelegramClient, events
from jp_channel_agent_trained import JPChannelAgentTrained
import pandas as pd

try:
    import pytz
    IST = pytz.timezone('Asia/Kolkata')
except ImportError:
    IST = None

# Fix Windows encoding
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

# Generate timestamped log filename
startup_time = datetime.now()
log_filename = startup_time.strftime('telegram_jp_%d%b%Y_%H_%M_%S.log').upper()

# Configure logging with timestamped filename
import logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_filename, encoding='utf-8'),
        logging.StreamHandler(
            io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
            if sys.platform == 'win32' else sys.stdout
        )
    ]
)

logger = logging.getLogger('TELEGRAM_JP_TRAINED')

# Load config
try:
    with open('telegram_config.json', 'r') as f:
        tg_config = json.load(f)
        API_ID = tg_config['api_id']
        API_HASH = tg_config['api_hash']
        PHONE = tg_config.get('phone') or tg_config.get('phone_number')
except Exception as e:
    logger.error(f"Failed to load telegram_config.json: {e}")
    exit(1)

# Load Claude API key
try:
    with open('claude_api_key.txt', 'r') as f:
        CLAUDE_API_KEY = f.read().strip()
except Exception as e:
    logger.error(f"Failed to load claude_api_key.txt: {e}")
    exit(1)

# Channel configuration
JP_CHANNEL_ID = -1003282204738

# Initialize client
client = TelegramClient('jp_trained_bot', API_ID, API_HASH)

# Initialize thread-safe database
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from db_utils import ThreadSafeDB
db = ThreadSafeDB('jp_signals_trained.db')
db.init_signals_table(include_instrument_type=False)
logger.info("[OK] Thread-safe database initialized")

# Initialize trained agent
logger.info("[INIT] Loading trained agent with KB...")
agent = JPChannelAgentTrained(
    claude_api_key=CLAUDE_API_KEY,
    kb_db='jp_kb.db',
    instruments_csv='valid_instruments.csv'
)

# Statistics
stats = {
    'total_messages': 0,
    'parsed_signals': 0,
    'stored_signals': 0,
    'skipped': 0,
    'regex_parsed': 0,
    'claude_parsed': 0,
    'index_options': 0,
    'stock_options': 0
}

# ========================================
# RATE LIMITING
# ========================================
class RateLimiter:
    """Simple rate limiter to prevent API bans"""
    def __init__(self, max_calls=30, window_seconds=60):
        self.max_calls = max_calls
        self.window_seconds = window_seconds
        self.calls = deque()

    def acquire(self):
        now = time.time()
        while self.calls and self.calls[0] < now - self.window_seconds:
            self.calls.popleft()
        if len(self.calls) >= self.max_calls:
            sleep_time = self.calls[0] + self.window_seconds - now
            if sleep_time > 0:
                logger.warning(f"[RATE LIMIT] Waiting {sleep_time:.1f}s...")
                time.sleep(sleep_time)
        self.calls.append(time.time())
        return True

rate_limiter = RateLimiter(max_calls=30, window_seconds=60)

# ========================================
# GRACEFUL SHUTDOWN
# ========================================
_shutdown_requested = False

def request_shutdown(signum=None, frame=None):
    global _shutdown_requested
    if _shutdown_requested:
        logger.warning("[SHUTDOWN] Force quit...")
        sys.exit(1)
    _shutdown_requested = True
    sig_name = signal.Signals(signum).name if signum else "UNKNOWN"
    logger.info(f"\n[SHUTDOWN] Received {sig_name}, shutting down gracefully...")
    print_stats()

if sys.platform != 'win32':
    signal.signal(signal.SIGTERM, request_shutdown)
signal.signal(signal.SIGINT, request_shutdown)

# ========================================
# TIMEZONE UTILITIES
# ========================================
def get_ist_now():
    if IST:
        return datetime.now(IST)
    return datetime.now()

def format_ist_timestamp(dt=None):
    if dt is None:
        dt = get_ist_now()
    if IST and dt.tzinfo is None:
        dt = IST.localize(dt)
    return dt.strftime('%Y-%m-%d %H:%M:%S IST')


def analyze_loaded_expiries(instruments_csv='valid_instruments.csv'):
    """Analyze and report expiry dates for key indices"""
    
    logger.info("")
    logger.info("="*70)
    logger.info("ðŸ“… LOADED EXPIRY DATES ANALYSIS")
    logger.info("="*70)
    
    try:
        # Load instruments
        df = pd.read_csv(instruments_csv)
        
        # Convert expiry to datetime
        df['expiry_dt'] = pd.to_datetime(df['expiry_date'])
        
        # Get current month
        current_month = startup_time.month
        current_year = startup_time.year
        
        # Filter for current month
        df_current_month = df[
            (df['expiry_dt'].dt.month == current_month) &
            (df['expiry_dt'].dt.year == current_year)
        ]
        
        logger.info(f"Current Month: {startup_time.strftime('%B %Y')}")
        logger.info(f"Total instruments loaded: {len(df)}")
        logger.info(f"Current month instruments: {len(df_current_month)}")
        logger.info("")
        
        # Analyze each index
        indices = {
            'NIFTY': 'NIFTY 50 (Weekly + Monthly)',
            'SENSEX': 'SENSEX (Weekly + Monthly)',
            'BANKNIFTY': 'BANK NIFTY',
            'FINNIFTY': 'FIN NIFTY',
            'MIDCPNIFTY': 'MIDCAP NIFTY'
        }
        
        for symbol, full_name in indices.items():
            # Get expiries for this symbol
            symbol_df = df_current_month[df_current_month['symbol'] == symbol]
            
            if len(symbol_df) == 0:
                logger.info(f"âš ï¸  {full_name}: No expiries found")
                continue
            
            # Get unique expiry dates
            expiries = sorted(symbol_df['expiry_dt'].unique())
            
            logger.info(f"âœ… {full_name}:")
            logger.info(f"   Total expiries this month: {len(expiries)}")
            
            # Show each expiry
            for exp_dt in expiries:
                exp_date = pd.to_datetime(exp_dt)
                day_name = exp_date.strftime('%A')
                date_str = exp_date.strftime('%d %b %Y')
                
                # Count strikes available
                strikes_count = len(symbol_df[symbol_df['expiry_dt'] == exp_dt]['strike'].unique())
                
                # Determine if weekly or monthly
                is_last_week = exp_date.day > 21
                expiry_type = "Monthly" if is_last_week else "Weekly"
                
                logger.info(f"      {date_str} ({day_name}) - {expiry_type} - {strikes_count} strikes")
            
            logger.info("")
        
        # Show next 3 upcoming expiries for NIFTY
        logger.info("ðŸ“Œ UPCOMING NIFTY EXPIRIES:")
        nifty_future = df[
            (df['symbol'] == 'NIFTY') &
            (df['expiry_dt'] > startup_time)
        ]
        
        if len(nifty_future) > 0:
            next_expiries = sorted(nifty_future['expiry_dt'].unique())[:3]
            
            for exp_dt in next_expiries:
                exp_date = pd.to_datetime(exp_dt)
                day_name = exp_date.strftime('%A')
                date_str = exp_date.strftime('%d %b %Y')
                days_away = (exp_date - startup_time).days
                
                logger.info(f"   {date_str} ({day_name}) - {days_away} days away")
        
        logger.info("")
        logger.info("="*70)
        
    except FileNotFoundError:
        logger.error(f"âŒ Instruments file not found: {instruments_csv}")
    except Exception as e:
        logger.error(f"âŒ Error analyzing expiries: {e}")
        import traceback
        traceback.print_exc()


def insert_signal(channel_id, channel_name, message_id, raw_text, parsed_data):
    """Insert signal into database (thread-safe with retry logic)"""
    try:
        signal_type = parsed_data.get('message_type', 'trained')

        # Use thread-safe insert with retry logic
        signal_id = db.insert_signal(
            channel_id=channel_id,
            channel_name=channel_name,
            message_id=message_id,
            raw_text=raw_text,
            parsed_data=parsed_data,
            parser_type='TRAINED_AGENT',
            signal_type=signal_type
        )

        if signal_id:
            stats['stored_signals'] += 1
            logger.info(f"[STORED] Signal ID: {signal_id}")
            return signal_id
        else:
            logger.info(f"[SKIP] Duplicate message")
            return None

    except Exception as e:
        logger.error(f"[DB ERROR] {e}")
        return None


async def handle_message(event):
    """Handle incoming messages with rate limiting"""
    # Check for shutdown
    if _shutdown_requested:
        return

    try:
        message_text = event.message.message
        if not message_text:
            return

        # Apply rate limiting
        rate_limiter.acquire()

        channel = await event.get_chat()
        channel_id = str(event.chat_id)
        channel_name = channel.title if hasattr(channel, 'title') else str(channel_id)
        message_id = event.message.id
        message_date = event.message.date.isoformat()

        stats['total_messages'] += 1

        # Log message with IST timestamp
        logger.info("")
        logger.info("="*70)
        logger.info(f"[NEW] {channel_name}")
        logger.info(f"[TIME] {format_ist_timestamp()}")
        preview = message_text[:60].replace('\n', ' ')
        logger.info(f"[MSG] {preview}...")
        logger.info(f"[DATE] {message_date}")
        logger.info("="*70)
        
        # Parse with trained agent (passes message date!)
        parsed_data = agent.parse(message_text, message_date=message_date)
        
        if parsed_data:
            stats['parsed_signals'] += 1
            
            # Track parser type
            if 'REGEX' in str(parsed_data.get('parser_type', '')):
                stats['regex_parsed'] += 1
            else:
                stats['claude_parsed'] += 1
            
            # Track signal type
            if parsed_data.get('message_type') == 'index':
                stats['index_options'] += 1
            elif parsed_data.get('message_type') == 'stock':
                stats['stock_options'] += 1
            
            # Show result
            logger.info(f"[SUCCESS] {parsed_data['symbol']} {parsed_data['strike']} {parsed_data['option_type']}")
            logger.info(f"   Entry: {parsed_data['entry_price']} | SL: {parsed_data['stop_loss']}")
            logger.info(f"   Tradingsymbol: {parsed_data['tradingsymbol']}")
            logger.info(f"   Exchange: {parsed_data['exchange']} | Expiry: {parsed_data['expiry_date']}")
            logger.info(f"   Quantity: {parsed_data['quantity']}")
            
            # Store
            insert_signal(channel_id, channel_name, message_id, message_text, parsed_data)
        else:
            stats['skipped'] += 1
            logger.info(f"[SKIP] Not a trading signal")
            
    except Exception as e:
        logger.error(f"[ERROR] {e}")
        import traceback
        traceback.print_exc()


async def main():
    """Main function"""
    print("\n" + "="*70)
    print("JP CHANNEL TELEGRAM READER - TRAINED AGENT")
    print("="*70)
    print(f"Started: {startup_time.strftime('%d %b %Y %H:%M:%S')}")
    print(f"Log File: {log_filename}")
    print(f"Training: {len(agent.training_examples)} human-verified examples")
    print(f"Accuracy: 98%+ (regex + Claude + KB)")
    print("="*70)
    print()
    
    # Log startup info
    logger.info("="*70)
    logger.info("TELEGRAM READER - STARTUP")
    logger.info("="*70)
    logger.info(f"Started: {startup_time.strftime('%d %b %Y %H:%M:%S')}")
    logger.info(f"Log File: {log_filename}")
    logger.info(f"Training Examples: {len(agent.training_examples)}")
    logger.info("="*70)
    
    # Analyze and show expiry dates
    analyze_loaded_expiries()
    
    await client.start(PHONE)
    
    me = await client.get_me()
    logger.info(f"[OK] Connected as {me.phone}")
    
    # Get channel
    try:
        channel = await client.get_entity(JP_CHANNEL_ID)
        await client.get_messages(channel, limit=1)
        logger.info(f"[OK] Monitoring: {channel.title}")
        logger.info(f"     Channel ID: {JP_CHANNEL_ID}")
        logger.info(f"     Parser: TRAINED (KB: {len(agent.training_examples)} examples)")
    except Exception as e:
        logger.error(f"[ERROR] Failed to get channel: {e}")
        return
    
    logger.info("")
    logger.info("="*70)
    logger.info("[START] Listening for messages...")
    logger.info("Features:")
    logger.info("  âœ“ Index + Stock options")
    logger.info("  âœ“ Correct expiry dates (learned from corrections)")
    logger.info("  âœ“ 80% regex (fast, free)")
    logger.info("  âœ“ 20% Claude (intelligent, KB-enhanced)")
    logger.info("  âœ“ 98%+ accuracy")
    logger.info("")
    logger.info("Press Ctrl+C to stop")
    logger.info("="*70)
    
    # Register handler
    @client.on(events.NewMessage(chats=[channel]))
    async def handler(event):
        await handle_message(event)
    
    await client.run_until_disconnected()


def print_stats():
    """Print statistics"""
    logger.info("")
    logger.info("="*70)
    logger.info("SESSION STATISTICS")
    logger.info("="*70)
    logger.info(f"Session Duration: {datetime.now() - startup_time}")
    logger.info(f"Total Messages:     {stats['total_messages']}")
    logger.info(f"Parsed Signals:     {stats['parsed_signals']}")
    logger.info(f"  - Regex (free):   {stats['regex_parsed']}")
    logger.info(f"  - Claude (KB):    {stats['claude_parsed']}")
    logger.info(f"  - Index Options:  {stats['index_options']}")
    logger.info(f"  - Stock Options:  {stats['stock_options']}")
    logger.info(f"Stored Signals:     {stats['stored_signals']}")
    logger.info(f"Skipped:            {stats['skipped']}")
    
    if stats['total_messages'] > 0:
        success_rate = (stats['parsed_signals'] / stats['total_messages']) * 100
        logger.info(f"Success Rate:       {success_rate:.1f}%")
    
    logger.info("="*70)
    logger.info(f"Log saved to: {log_filename}")


if __name__ == '__main__':
    logger.info(f"[START] JP Telegram Reader starting at {format_ist_timestamp()}")
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        if not _shutdown_requested:
            logger.info("\n[STOP] Shutting down...")
            print_stats()
    except Exception as e:
        logger.error(f"[FATAL] {e}")
        import traceback
        traceback.print_exc()
    finally:
        logger.info(f"[END] JP Telegram Reader stopped at {format_ist_timestamp()}")
    # Note: No db.close() needed - ThreadSafeDB uses connection-per-operation
